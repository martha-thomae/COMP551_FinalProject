{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_bag_of_words(idfile, nwords=5000):\n",
    "    with open(idfile, 'r') as textfile:\n",
    "        num_reviews = len(textfile.readlines())\n",
    "\n",
    "    frequency_bow = np.zeros((num_reviews, nwords)) # The entries will be floating points (because it is a relative probability, so its a decimal between 0 and 1)\n",
    "    yvector = np.array([], dtype=int)\n",
    "\n",
    "    with open(idfile, 'r') as textfile:\n",
    "        for n, line in enumerate(textfile):\n",
    "            # Store the relative frequency features for the n-th review\n",
    "            words = line.split()\n",
    "            words_ids = words[1:] # Use every single entry, but the first one (since all entries are ids, except for the first one which is the class)\n",
    "            words_ids = list(map(int, words_ids))\n",
    "            relfreq, bins = np.histogram(words_ids, bins=[i for i in range(1, nwords+2)]) # range(1,5002) = [1, 2, 3, ..., 5000, 5001] --> resulting in classes 1, 2, 3, ..., 5000\n",
    "            total = np.sum(relfreq)\n",
    "\n",
    "            # Condition to avoid division by zero\n",
    "            # Example: when a line contains a single word (\"D-scust-ing\", probably meaning \"disgusting\"), \n",
    "            # which is not in the vocabulary and, therefore, the 'total' variable for this row has a value of 0\n",
    "            if total == 0:\n",
    "                print(idfile, n)\n",
    "                pass\n",
    "            else: \n",
    "                frequency_bow[n] = relfreq / total\n",
    "\n",
    "            # Target vector\n",
    "            yvector = np.append([yvector], int(words[0])) # Use the first entry (i.e., the true label)\n",
    "\n",
    "    return frequency_bow, yvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frequency bag of words matrix and the target vector\n",
    "\n",
    "# AG News Dataset\n",
    "\n",
    "#get_frequency_bag_of_words(idfile, nwords=5000)\n",
    "train_freqbow, ytrain_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/agnews-train.txt\")\n",
    "print(\"\\n\\nTrain\\n\\nFrequency Bag-of-Wors\")\n",
    "print(train_freqbow)\n",
    "print(train_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytrain_true)\n",
    "print(ytrain_true.shape)\n",
    "\n",
    "test_freqbow, ytest_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/agnews-test.txt\")\n",
    "print(\"\\n\\nTest\\n\\nFrequency Bag-of-Words\")\n",
    "print(test_freqbow)\n",
    "print(test_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytest_true)\n",
    "print(ytest_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBpedia Dataset\n",
    "\n",
    "#get_frequency_bag_of_words(idfile, nwords=5000)\n",
    "train_freqbow, ytrain_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/dbpedia-train.txt\")\n",
    "print(\"\\n\\nTrain\\n\\nFrequency Bag-of-Wors\")\n",
    "print(train_freqbow)\n",
    "print(train_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytrain_true)\n",
    "print(ytrain_true.shape)\n",
    "\n",
    "test_freqbow, ytest_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/dbpedia-test.txt\")\n",
    "print(\"\\n\\nTest\\n\\nFrequency Bag-of-Words\")\n",
    "print(test_freqbow)\n",
    "print(test_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytest_true)\n",
    "print(ytest_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahoo Answers Dataset\n",
    "\n",
    "#get_frequency_bag_of_words(idfile, nwords=5000)\n",
    "train_freqbow, ytrain_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/yahoo_answers-train.txt\")\n",
    "print(\"\\n\\nTrain\\n\\nFrequency Bag-of-Wors\")\n",
    "print(train_freqbow)\n",
    "print(train_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytrain_true)\n",
    "print(ytrain_true.shape)\n",
    "\n",
    "test_freqbow, ytest_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/yahoo_answers-test.txt\")\n",
    "print(\"\\n\\nTest\\n\\nFrequency Bag-of-Words\")\n",
    "print(test_freqbow)\n",
    "print(test_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytest_true)\n",
    "print(ytest_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Reviews (Full) Dataset\n",
    "\n",
    "#get_frequency_bag_of_words(idfile, nwords=5000)\n",
    "train_freqbow, ytrain_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/amazon_review_full-train.txt\")\n",
    "print(\"\\n\\nTrain\\n\\nFrequency Bag-of-Wors\")\n",
    "print(train_freqbow)\n",
    "print(train_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytrain_true)\n",
    "print(ytrain_true.shape)\n",
    "\n",
    "test_freqbow, ytest_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/amazon_review_full-test.txt\")\n",
    "print(\"\\n\\nTest\\n\\nFrequency Bag-of-Words\")\n",
    "print(test_freqbow)\n",
    "print(test_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytest_true)\n",
    "print(ytest_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Reviews (Polarity) Dataset\n",
    "\n",
    "#get_frequency_bag_of_words(idfile, nwords=5000)\n",
    "train_freqbow, ytrain_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/amazon_review_polarity-train.txt\")\n",
    "print(\"\\n\\nTrain\\n\\nFrequency Bag-of-Wors\")\n",
    "print(train_freqbow)\n",
    "print(train_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytrain_true)\n",
    "print(ytrain_true.shape)\n",
    "\n",
    "test_freqbow, ytest_true = get_frequency_bag_of_words(\"../Output/Dataset_with_ids/amazon_review_polarity-test.txt\")\n",
    "print(\"\\n\\nTest\\n\\nFrequency Bag-of-Words\")\n",
    "print(test_freqbow)\n",
    "print(test_freqbow.shape)\n",
    "print(\"\\nTarget Vector\")\n",
    "print(ytest_true)\n",
    "print(ytest_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
