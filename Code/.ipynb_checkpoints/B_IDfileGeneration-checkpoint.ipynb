{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformatting of <span style=\"color:brown\">Train/Valid/Test Files</span> as Matrices of IDs of the Words Included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_dictionary(vocabfile, nwords=5000):\n",
    "    \"\"\"\n",
    "    Get a dictionary from the vocabulary file (which contains the top 10k most common words in the training set)\n",
    "    By default this dictionary contains the top 5k most common words, using: (key, value) = (word, id)\n",
    "    \"\"\"\n",
    "    vocab_dict = {}\n",
    "    with open(vocabfile, \"r\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if i < nwords:\n",
    "                (word, idnum) = line.split()[0:2]\n",
    "                vocab_dict[word] = idnum\n",
    "            else:\n",
    "                break\n",
    "            i = i + 1\n",
    "    return vocab_dict\n",
    "\n",
    "\n",
    "def get_file_of_ids(input_file, output_file, vocab_dict):\n",
    "    \"\"\" \n",
    "    Translate the original csv file into a file of ids (here store in the 'idtext' variable)\n",
    "    Each entry of the file looks like this: label_number, sequence_of_ids\n",
    "    Where the label_number is separated from the sequence_of_ids by a tabulation\n",
    "    And the ids in the sequence_of_ids are separated by spaces.\n",
    "    \"\"\"\n",
    "    # Output file of ids corresponding to the ids of the words in the dictionary\n",
    "    with open(output_file, \"w\") as idtext:\n",
    "   \n",
    "        # The original csv file (with the original text)\n",
    "        with open(input_file) as origtext:\n",
    "            reader = csv.reader(origtext)\n",
    "            \n",
    "            for row in reader:               \n",
    "                # A) Write the class\n",
    "                idtext.write(row[0])\n",
    "                idtext.write('\\t')\n",
    "\n",
    "                # B) Write the ids of the corresponding text (cells of the row from columns 1 onward)\n",
    "                # B.1) Join all cells after the first one (which has the label), since these contain the text\n",
    "                text_in_row = ' '.join(row[1:])\n",
    "                # B.2) Preprocessing: Removal of punctuation, and lower case\n",
    "                text_in_row = ''.join(re.findall(\"[a-zA-Z0-9 '-]*\", text_in_row)).lower()\n",
    "                # B.3) Get all the words (list)\n",
    "                words_in_row = text_in_row.split()\n",
    "                # B.4) For each of the words in the review:\n",
    "                for word in words_in_row:\n",
    "                    # Determine if the word appears in the vocabulary \n",
    "                    try:\n",
    "                        idtext.write(vocab_dict[word]) # That is the ID of the word\n",
    "                        idtext.write(\" \")\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "                # Next line (row)\n",
    "                idtext.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the previous functions to generate the train, valid, and test text files that \n",
    "# contain a sequence of ids corresponding to the words in each review for the datasets\n",
    "\n",
    "# AG News Dataset\n",
    "agnews_dict = get_vocab_dictionary(\"../Output/Vocabulary/ag_news.txt\")\n",
    "\n",
    "#get_file_of_ids(input_file, output_file, vocab_dict)\n",
    "get_file_of_ids(\"../Datasets/ag_news_csv/train.csv\", \"../Output/Dataset_with_ids/agnews-train.txt\", agnews_dict)\n",
    "get_file_of_ids(\"../Datasets/ag_news_csv/test.csv\", \"../Output/Dataset_with_ids/agnews-test.txt\", agnews_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBpedia Dataset\n",
    "dbpedia_dict = get_vocab_dictionary(\"../Output/Vocabulary/dbpedia.txt\")\n",
    "\n",
    "#get_file_of_ids(input_file, output_file, vocab_dict)\n",
    "get_file_of_ids(\"../Datasets/dbpedia_csv/train.csv\", \"../Output/Dataset_with_ids/dbpedia-train.txt\", dbpedia_dict)\n",
    "get_file_of_ids(\"../Datasets/dbpedia_csv/test.csv\", \"../Output/Dataset_with_ids/dbpedia-test.txt\", dbpedia_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahoo Answers Dataset\n",
    "yahoo_answers_dict = get_vocab_dictionary(\"../Output/Vocabulary/yahoo_answers.txt\")\n",
    "\n",
    "#get_file_of_ids(input_file, output_file, vocab_dict)\n",
    "get_file_of_ids(\"../Datasets/yahoo_answers_csv/train.csv\", \"../Output/Dataset_with_ids/yahoo_answers-train.txt\", yahoo_answers_dict)\n",
    "get_file_of_ids(\"../Datasets/yahoo_answers_csv/test.csv\", \"../Output/Dataset_with_ids/yahoo_answers-test.txt\", yahoo_answers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Review (Full) Dataset\n",
    "amazon_review_full_dict = get_vocab_dictionary(\"../Output/Vocabulary/amazon_review_full.txt\")\n",
    "\n",
    "#get_file_of_ids(input_file, output_file, vocab_dict)\n",
    "get_file_of_ids(\"../Datasets/amazon_review_full_csv/train.csv\", \"../Output/Dataset_with_ids/amazon_review_full-train.txt\", amazon_review_full_dict)\n",
    "get_file_of_ids(\"../Datasets/amazon_review_full_csv/test.csv\", \"../Output/Dataset_with_ids/amazon_review_full-test.txt\", amazon_review_full_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Review (Polarity) Dataset\n",
    "amazon_review_polarity_dict = get_vocab_dictionary(\"../Output/Vocabulary/amazon_review_polarity.txt\")\n",
    "\n",
    "#get_file_of_ids(input_file, output_file, vocab_dict)\n",
    "get_file_of_ids(\"../Datasets/amazon_review_polarity_csv/train.csv\", \"../Output/Dataset_with_ids/amazon_review_polarity-train.txt\", amazon_review_polarity_dict)\n",
    "get_file_of_ids(\"../Datasets/amazon_review_polarity_csv/test.csv\", \"../Output/Dataset_with_ids/amazon_review_polarity-test.txt\", amazon_review_polarity_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
